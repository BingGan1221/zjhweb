import streamlit as st

# è®¾ç½®é¡µé¢é…ç½®å¿…é¡»æ˜¯ç¬¬ä¸€ä¸ª Streamlit å‘½ä»¤
st.set_page_config(
    page_title="Excelè¯„è®ºåˆ†æå·¥å…·",
    page_icon="ğŸ“Š",
    layout="wide"
)

import sys
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# æ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯
st.write(f"Python ç‰ˆæœ¬: {sys.version}")
logger.info(f"Python ç‰ˆæœ¬: {sys.version}")

try:
    import pandas as pd
    import numpy as np
    from collections import Counter
    from pathlib import Path
    import shutil
    import requests
    import plotly.express as px
    
    logger.info("åŸºç¡€ä¾èµ–åŒ…å¯¼å…¥æˆåŠŸ")
except Exception as e:
    logger.error(f"åŸºç¡€ä¾èµ–åŒ…å¯¼å…¥å¤±è´¥: {str(e)}")
    st.error(f"åŸºç¡€ä¾èµ–åŒ…å¯¼å…¥å¤±è´¥: {str(e)}")
    st.stop()

try:
    from wordcloud import WordCloud
    logger.info("WordCloud å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    logger.error(f"WordCloud å¯¼å…¥å¤±è´¥: {str(e)}")
    st.error("æ— æ³•å¯¼å…¥ WordCloud åŒ…ï¼Œè¯·æ£€æŸ¥ä¾èµ–å®‰è£…")
    st.stop()

try:
    import jieba
    logger.info("jieba å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    logger.error(f"jieba å¯¼å…¥å¤±è´¥: {str(e)}")
    st.error("æ— æ³•å¯¼å…¥ jieba åŒ…ï¼Œè¯·æ£€æŸ¥ä¾èµ–å®‰è£…")
    st.stop()

# å®šä¹‰åœç”¨è¯åˆ—è¡¨
STOP_WORDS = {
    'çš„', 'äº†', 'å’Œ', 'æ˜¯', 'å°±', 'éƒ½', 'è€Œ', 'åŠ', 'ä¸', 'ç€',
    'ä¹‹', 'ç”¨', 'äº', 'æŠŠ', 'ç­‰', 'å»', 'åˆ', 'èƒ½', 'å¥½', 'åœ¨',
    'æˆ–', 'è¿™', 'é‚£', 'æœ‰', 'å¾ˆ', 'åª', 'äº›', 'ä¸º', 'å‘¢', 'å•Š',
    'å¹¶', 'ç»™', 'è·Ÿ', 'è¿˜', 'ä¸ª', 'ä¹‹ç±»', 'å„ç§', 'æ²¡æœ‰', 'éå¸¸',
    'å¯ä»¥', 'å› ä¸º', 'å› æ­¤', 'æ‰€ä»¥', 'ä½†æ˜¯', 'ä½†', 'ç„¶å', 'å¦‚æœ',
    'è™½ç„¶', 'è¿™æ ·', 'è¿™äº›', 'é‚£äº›', 'å¦‚æ­¤', 'åªæ˜¯', 'çœŸçš„', 'ä¸€ä¸ª',
}

def ensure_font():
    font_dir = Path('fonts')
    font_path = font_dir / 'simhei.ttf'
    
    if font_path.exists():
        return str(font_path)
    
    font_dir.mkdir(exist_ok=True)
    
    system_fonts = [
        Path('C:/Windows/Fonts/simhei.ttf'),
        Path('/usr/share/fonts/truetype/simhei.ttf'),
        Path('/System/Library/Fonts/simhei.ttf')
    ]
    
    for system_font in system_fonts:
        if system_font.exists():
            shutil.copy(system_font, font_path)
            return str(font_path)
    
    try:
        font_url = "https://github.com/microsoft/Windows-Font/raw/master/SimHei.ttf"
        response = requests.get(font_url)
        response.raise_for_status()
        
        with open(font_path, 'wb') as f:
            f.write(response.content)
        
        return str(font_path)
        
    except Exception as e:
        st.error(f"è·å–å­—ä½“æ–‡ä»¶å¤±è´¥: {str(e)}")
        return None

def highlight_words(text, selected_word):
    """åªé«˜äº®é€‰ä¸­çš„å…³é”®è¯"""
    # ä½¿ç”¨ HTML æ ‡ç­¾è€Œä¸æ˜¯ Markdown
    return text.replace(selected_word, f'<span style="color: red; font-weight: bold;">{selected_word}</span>')

def get_most_complete_comment(comments):
    """ä»ç›¸ä¼¼è¯„è®ºä¸­é€‰æ‹©æœ€é•¿çš„ä¸€æ¡ï¼ˆé€šå¸¸æ˜¯æœ€å®Œæ•´çš„ï¼‰"""
    normalized_comments = {}
    for comment in comments:
        normalized = ' '.join(comment.split())  # è§„èŒƒåŒ–ç©ºç™½å­—ç¬¦
        # å¦‚æœå·²å­˜åœ¨ç›¸ä¼¼è¯„è®ºï¼Œä¿ç•™è¾ƒé•¿çš„é‚£ä¸ª
        if normalized in normalized_comments:
            if len(comment) > len(normalized_comments[normalized]):
                normalized_comments[normalized] = comment
        else:
            normalized_comments[normalized] = comment
    return list(normalized_comments.values())

def main():
    # åŠ è½½è‡ªå®šä¹‰CSS
    with open('.streamlit/style.css') as f:
        st.markdown(f'<style>{f.read()}</style>', unsafe_allow_html=True)
    
    # é¡µé¢æ ‡é¢˜
    st.markdown("""
    <div class="title-container">
        <h1 class="title-text">ğŸ“Š Excelè¯„è®ºåˆ†æå·¥å…·</h1>
        <p class="subtitle-text">å¿«é€Ÿåˆ†æå’Œå¯è§†åŒ–æ‚¨çš„è¯„è®ºæ•°æ®</p>
    </div>
    """, unsafe_allow_html=True)
    
    # ä½¿ç”¨æŒ‡å—éƒ¨åˆ†
    st.markdown("""
    <div class="guide-container">
        <h4 class="guide-title">ğŸ“ ä½¿ç”¨æŒ‡å—</h4>
        <div class="guide-grid">
            <div class="guide-item">
                <p>1. ä¸Šä¼ Excelæ–‡ä»¶ï¼ˆ.xlsxæ ¼å¼ï¼‰</p>
            </div>
            <div class="guide-item">
                <p>2. ç³»ç»Ÿè‡ªåŠ¨åˆ†æè¯„è®ºå†…å®¹å’Œè¯„åˆ†</p>
            </div>
            <div class="guide-item">
                <p>3. æŸ¥çœ‹è¯äº‘å›¾å’Œè¯é¢‘ç»Ÿè®¡</p>
            </div>
            <div class="guide-item">
                <p>4. é€‰æ‹©å…³é”®è¯æŸ¥çœ‹ç›¸å…³è¯„è®º</p>
            </div>
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    # æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
    st.markdown('<div class="upload-container">', unsafe_allow_html=True)
    uploaded_file = st.file_uploader(
        "é€‰æ‹©Excelæ–‡ä»¶ä¸Šä¼ ",
        type=['xlsx'],
        help="è¯·ä¸Šä¼ åŒ…å«è¯„è®ºæ•°æ®çš„Excelæ–‡ä»¶ï¼ˆ.xlsxæ ¼å¼ï¼‰"
    )
    st.markdown('</div>', unsafe_allow_html=True)
    
    if uploaded_file:
        try:
            df = pd.read_excel(uploaded_file, header=5)
            
            score_col = None
            for col in df.columns:
                if 'æ€»å®‰æ’æ‰“åˆ†' in str(col):
                    score_col = col
                    break
            
            if score_col is None:
                st.error('æœªæ‰¾åˆ°"æ€»å®‰æ’æ‰“åˆ†"åˆ—')
                return
            
            comments = df.iloc[:, 0]
            scores = df[score_col]
            
            total_comments = len(comments)
            low_score_comments = sum(1 for score in scores if score <= 3)
            
            # ç»Ÿè®¡æŒ‡æ ‡æ˜¾ç¤º
            st.markdown("""
            <div class="stats-container">
                <div class="stat-card">
                    <h3>æ€»è¯„è®ºæ•°</h3>
                    <h2>{total_comments}</h2>
                </div>
                <div class="stat-card stat-card-red">
                    <h3>å·®è¯„æ•°é‡</h3>
                    <h2>{low_score_comments}</h2>
                </div>
            </div>
            """, unsafe_allow_html=True)
            
            word_freq = Counter()
            word_freq_low = Counter()
            word_comments = {}  # å­˜å‚¨æ¯ä¸ªè¯å¯¹åº”çš„è®ºåˆ—è¡¨
            word_comments_low = {}  # å­˜å‚¨æ¯ä¸ªè¯å¯¹åº”çš„å·®è¯„åˆ—è¡¨
            
            for comment, score in zip(comments, scores):
                if pd.isna(comment) or pd.isna(score):
                    continue
                    
                comment = str(comment).strip()
                if not comment:
                    continue
                
                words = jieba.cut(comment)
                comment_words = set()  # ç”¨äºè®°å½•å½“å‰è¯„è®ºä¸­çš„é«˜é¢‘è¯
                
                for word in words:
                    word = word.strip()
                    if (len(word) > 1 and
                        word not in STOP_WORDS and
                        not word.isdigit()):
                        
                        word_freq[word] += 1
                        comment_words.add(word)
                        if word not in word_comments:
                            word_comments[word] = set()  # ä½¿ç”¨é›†åˆé¿å…é‡å¤
                        word_comments[word].add(comment)
                        
                        if score <= 3:
                            word_freq_low[word] += 1
                            if word not in word_comments_low:
                                word_comments_low[word] = set()  # ä½¿ç”¨é›†åˆé¿å…é‡å¤
                            word_comments_low[word].add(comment)
            
            # è¯äº‘åˆ†æéƒ¨åˆ†
            if word_freq:
                st.markdown("""
                <div class="analysis-section">
                    <h3 class="section-title">è¯äº‘åˆ†æ</h3>
                    <div class="wordcloud-container">
                        <!-- è¯äº‘å›¾å°†åœ¨è¿™é‡Œæ˜¾ç¤º -->
                    </div>
                </div>
                """, unsafe_allow_html=True)
                
                # è¯äº‘å›¾ç”Ÿæˆä»£ç 
                if word_freq:
                    st.markdown("""
                    <h3 style='color: #2E86C1; margin: 2rem 0 1rem 0;'>è¯äº‘å›¾</h3>
                    """, unsafe_allow_html=True)
                    wc = WordCloud(
                        font_path=ensure_font(),
                        width=800,
                        height=400,
                        background_color='white',
                        max_words=100
                    )
                    wc.generate_from_frequencies(word_freq)
                    st.image(wc.to_array())
                    
                    st.markdown("""
                    <h3 style='color: #2E86C1; margin: 2rem 0 1rem 0;'>è¯é¢‘ç»Ÿè®¡</h3>
                    """, unsafe_allow_html=True)
                    # ç¾åŒ–è¯é¢‘å›¾è¡¨
                    top_words = dict(sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:20])
                    fig = px.bar(
                        x=list(top_words.keys()),
                        y=list(top_words.values()),
                        title="è¯é¢‘ç»Ÿè®¡ï¼ˆå‰20ä¸ªè¯ï¼‰",
                        labels={'x': 'å…³é”®è¯', 'y': 'å‡ºç°æ¬¡æ•°'},
                        color_discrete_sequence=['#2E86C1']
                    )
                    fig.update_layout(
                        title_x=0.5,
                        title_font_size=20,
                        plot_bgcolor='rgba(0,0,0,0)',
                        paper_bgcolor='rgba(0,0,0,0)'
                    )
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # ç¾åŒ–é€‰æ‹©æ¡†å’Œè¯„è®ºæ˜¾ç¤º
                    st.markdown("<br>", unsafe_allow_html=True)
                    selected_word = st.selectbox(
                        "é€‰æ‹©å…³é”®è¯æŸ¥çœ‹ç›¸å…³è¯„è®º",
                        options=list(top_words.keys()),
                        help="é€‰æ‹©ä¸€ä¸ªå…³é”®è¯ï¼ŒæŸ¥çœ‹åŒ…å«è¯¥è¯çš„æ‰€æœ‰è¯„è®º"
                    )
                    
                    if selected_word:
                        st.markdown("""
                        <div class="comment-list">
                            <h4>åŒ…å« "{selected_word}" çš„è¯„è®ºï¼š</h4>
                            <!-- è¯„è®ºå°†åœ¨è¿™é‡Œæ˜¾ç¤º -->
                        </div>
                        """, unsafe_allow_html=True)
                        
                        # è·å–è¯„è®ºå¹¶ä¿ç•™æœ€å®Œæ•´çš„ç‰ˆæœ¬
                        relevant_comments = word_comments.get(selected_word, set())
                        unique_comments = get_most_complete_comment(relevant_comments)
                        
                        # æ˜¾ç¤ºå»é‡åçš„è¯„è®º
                        for comment in unique_comments:
                            st.markdown(f"""
                            <div class="comment-item">
                                {highlight_words(comment, selected_word)}
                            </div>
                            """, unsafe_allow_html=True)
            else:
                st.info("æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„è¯„è®ºæ•°æ®")
            
            # å·®è¯„åˆ†æéƒ¨åˆ†
            if word_freq_low:
                st.markdown("""
                <div class="analysis-section">
                    <h3 class="section-title">å·®è¯„åˆ†æ</h3>
                    <div class="wordcloud-container">
                        <!-- å·®è¯„è¯äº‘å›¾å°†åœ¨è¿™é‡Œæ˜¾ç¤º -->
                    </div>
                </div>
                """, unsafe_allow_html=True)
                
                # å·®è¯„è¯äº‘å›¾ç”Ÿæˆä»£ç 
                if word_freq_low:
                    st.markdown("""
                    <h3 style='color: #2E86C1; margin: 2rem 0 1rem 0;'>å·®è¯„è¯äº‘å›¾</h3>
                    """, unsafe_allow_html=True)
                    wc = WordCloud(
                        font_path=ensure_font(),
                        width=800,
                        height=400,
                        background_color='white',
                        max_words=100
                    )
                    wc.generate_from_frequencies(word_freq_low)
                    st.image(wc.to_array())
                    
                    st.markdown("""
                    <h3 style='color: #2E86C1; margin: 2rem 0 1rem 0;'>å·®è¯„è¯é¢‘ç»Ÿè®¡</h3>
                    """, unsafe_allow_html=True)
                    # ç¾åŒ–è¯é¢‘å›¾è¡¨
                    top_words = dict(sorted(word_freq_low.items(), key=lambda x: x[1], reverse=True)[:20])
                    fig = px.bar(
                        x=list(top_words.keys()),
                        y=list(top_words.values()),
                        title="å·®è¯„è¯é¢‘ç»Ÿè®¡ï¼ˆå‰20ä¸ªè¯ï¼‰",
                        labels={'x': 'å…³é”®è¯', 'y': 'å‡ºç°æ¬¡æ•°'},
                        color_discrete_sequence=['#2E86C1']
                    )
                    fig.update_layout(
                        title_x=0.5,
                        title_font_size=20,
                        plot_bgcolor='rgba(0,0,0,0)',
                        paper_bgcolor='rgba(0,0,0,0)'
                    )
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # ç¾åŒ–é€‰æ‹©æ¡†å’Œè¯„è®ºæ˜¾ç¤º
                    st.markdown("<br>", unsafe_allow_html=True)
                    selected_word = st.selectbox(
                        "é€‰æ‹©å…³é”®è¯æŸ¥çœ‹ç›¸å…³å·®è¯„",
                        options=list(top_words.keys()),
                        help="é€‰æ‹©ä¸€ä¸ªå…³é”®è¯ï¼ŒæŸ¥çœ‹åŒ…å«è¯¥è¯çš„æ‰€æœ‰å·®è¯„",
                        key="low_score_select"
                    )
                    
                    if selected_word:
                        st.markdown("""
                        <div class="comment-list">
                            <h4>åŒ…å« "{selected_word}" çš„å·®è¯„ï¼š</h4>
                            <!-- å·®è¯„å°†åœ¨è¿™é‡Œæ˜¾ç¤º -->
                        </div>
                        """, unsafe_allow_html=True)
                        
                        # è·å–å·®è¯„å¹¶å»é‡
                        relevant_comments = word_comments_low.get(selected_word, set())
                        # å°†è¯„è®ºå†…å®¹è§„èŒƒåŒ–ï¼ˆå»é™¤ç©ºæ ¼ã€æ¢è¡Œç­‰ï¼‰åå†å»é‡
                        normalized_comments = {}
                        for comment in relevant_comments:
                            normalized = ' '.join(comment.split())  # è§„èŒƒåŒ–ç©ºç™½å­—ç¬¦
                            normalized_comments[normalized] = comment  # ä½¿ç”¨åŸå§‹è¯„è®ºä½œä¸ºå€¼
                        
                        # æ˜¾ç¤ºå»é‡åçš„è¯„è®º
                        for original_comment in normalized_comments.values():
                            st.markdown(f"""
                            <div class="comment-item">
                                {highlight_words(original_comment, selected_word)}
                            </div>
                            """, unsafe_allow_html=True)
                else:
                    st.info("æ²¡æœ‰æ‰¾åˆ°å·®è¯„æ•°æ®")
                    
        except Exception as e:
            st.error(f"å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
    
    # é¡µè„š
    st.markdown("""
    <div class="footer">
        <p>ğŸ¨ Designed with ğŸ‘ @å°ç¾Š</p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()